#+TITLE: Homework 1
#+setupfile: ~/Dropbox/org/orbit/articles/setup_file.org

* Problem 1.1
\begin{align}
\min_{x_1,x_2} \quad & f(x_{1}, x_2) = (x_1-1)^2+2(x_2-2)^2, \\
\text{subject to} \quad &  g(x_1x_2) = x_1^2+x_2^2-1 \leq 0.
\end{align}

The penalty function takes the form
\begin{align*}
p(\mathbf{x};\mu) &= \mu(\sum_{i=1}^m (\max\{g_{i}(\mathbf{x}), 0\})^2) \\
&= \mu(\max\{g(\mathbf{x}), 0\})^2 \\
&= \mu(\max\{x_{1}^{2} + x_{2}^{2} - 1, 0\})^2.
\end{align*}

Thus
\begin{equation}
f_p(x_1,x_2;\mu) =
\begin{cases}
(x_1-1)^2+2(x_2-2)^2 + \mu(x_{1}^{2} + x_{2}^{2} - 1)^2 & \mbox{if $x_{1}^{2} + x_{2}^{2}> 1 $} ,\\
(x_1-1)^2+2(x_2-2)^2 & \mbox{otherwise.}\\
\end{cases}
\end{equation}

Next calculate the gradient
\begin{equation}
\nabla f_p(x_1,x_2;\mu) =
\begin{cases}
\begin{bmatrix}
2(x_1-1) + 4\mu(x_{1}^3 + x_1x_2^{2} - x_1) \\
4(x_2-2) + 4\mu(x_2^{3} + x_{1}^2x_{2} - x_2) \\
\end{bmatrix} & \mbox{if $x_{1}^{2} + x_{2}^{2}> 1 $} ,\\[4mm]
\begin{bmatrix}
2(x_1-1) \\
4(x_2-2) \\
\end{bmatrix} & \mbox{otherwise.} \\
\end{cases}
\end{equation}

For convex functions such as this one, the global minimum can be found simply
by setting the gradient to 0
\begin{align}
\nabla f_{p}(\mathbf{x};\mu = 0) = 0 \Rightarrow f_{p}^{\ast} = (x_1^{\ast}, x_2^{\ast}) = \left(\frac{1}{2}, \frac{1}{2}\right).
\end{align}

* Problem 1.2
** Task a
\begin{equation}
f(x_1,x_2) = 4x_1^2 - x_1x_2 + 4x_2^2 - 6x_2
\end{equation}

Compute the gradient
\begin{equation}
\nabla f(x_1,x_2) =
\begin{bmatrix}
8x_1^2-x_2 \\
-x_1+8x_2-6
\end{bmatrix}
\end{equation}

Then, consider candidates in the interior of the surface by finding stationary points
\begin{align*}
\nabla f(x_{1}, x_{2}) =
\begin{cases}
8x_1^2-x_2 = 0 \\
-x_1+8x_2-6 = 0
\end{cases}
\Rightarrow
& 64x_2 - x_2 = 48 \\
& x_2 = \frac{48}{63}, x_1 = \frac{2}{21}
\end{align*}
which is inside the surface.

Now evaluate the gradient at the corners to check if they are stationary points
\begin{align*}
\nabla f(0,0) &= (0, -6)^{T} &\mbox{No candidate}\\
\nabla f(0,1) &= (1, 2)^{T} &\mbox{No candidate}\\
\nabla f(1,1) &= (7,1)^{T} &\mbox{No candidate}\\
\end{align*}

Next consider the edges of the surface
- Line $(0,0)$ to $(1,1)$ :: Constraint $0 < x_1 < 1, x_2 = x_1$
\begin{align*}
f(x_{1}, x_{1}) &= 7x_1^2 - 6x_1\\
\frac{df}{dx_{1}} &= 14x_1 - 6 \\
\frac{df}{dx_{1}} &= 0 \Rightarrow x_{1} = \frac{3}{7} &
\mbox{Candidate $(\frac{3}{7}, \frac{3}{7})^{T}$}
\end{align*}
- Line $(0,0)$ to $(0,1)$ :: Constraint $x_1 = 0, 0 < x_2 < 1$
\begin{align*}
f(0, x_{2}) &= 4x_2^2 - 6x_2 \\
\frac{df}{dx_{2}} &= 8x_2 - 6 \\
\frac{df}{dx_{2}} &= 0 \Rightarrow x_{2} = \frac{6}{8} &
\mbox{Candidate $(0, \frac{6}{8})^{T}$}
\end{align*}
- Line $(0,1)$ to $(1,1)$ :: Constraint $0 < x_1 < 1, x_2 = 1$
\begin{align*}
f(x_1, 1) &= 4x_1^2 - x_1 - 2\\
\frac{df}{dx_{1}} &= 8x_{1} -1\\
\frac{df}{dx_{1}} &= 0 \Rightarrow x_{1} = \frac{1}{8} &
\mbox{Candidate $(\frac{1}{8}, 1)^{T}$}
\end{align*}

** Task b
The optimization problem is
\begin{align}
\min_{x_1,x_2} \quad & f(x_1, x_2) = 15 + 2x_{1} + 3x_{2} \\
\text{subject to} \quad & h(x_1, x_2) = x_1^2 + x_1x_2 + x_2^2-21 = 0,
\end{align}
and should be solved using the Lagrange multiplier method.

First define
\begin{equation}
L(x_1,x_2,\lambda) = f(x_1,x_2) + \lambda h(x_1,x_2).
\end{equation}

Next find the critical points of $L$ by calculating the gradient and setting it to 0
\begin{align*}
\nabla_{x_1,x_2,\lambda}L(x_1,x_2,\lambda) = 0 \Rightarrow
\begin{cases}
i) & \frac{\partial L}{\partial x_{1}} = 2 + \lambda(2x_{1} + x_{2}) = 0 \\[1mm]
ii) & \frac{\partial L}{\partial x_{2}} = 3 + \lambda(x_{1} + 2x_{2}) = 0 \\[1mm]
iii) & \frac{\partial L}{\partial \lambda} = x_1^2 + x_1x_2 + x_2^2-21 = 0,
\end{cases}
\end{align*}
which results in a three equations, three variable system, which we can solve.

Do $i - 2ii$ and solve for $x_2$
\begin{align*}
2 + \lambda(2x_{1} + x_{2}) - 2(3 + \lambda(x_{1} + 2x_{2})) &= 0 \\
-3\lambda x_{2} &= 4 \\
x_{2} &= -\frac{4}{3\lambda}.
\end{align*}

Then, insert into Equation $ii$ and solve for $x_1$
\begin{align*}
\lambda x_{1} &= -3 - 2\lambda \left(-\frac{4}{3\lambda}\right)\\
x_1 &= -\frac{1}{3\lambda}.
\end{align*}

So
\begin{equation*}
\begin{cases}
x_{1} = -\frac{1}{3\lambda}\\
x_{2} = -\frac{4}{3\lambda}.
\end{cases}
\end{equation*}

Insert into Equation $iii$ and solve for $\lambda$
\begin{align*}
x_1^2 + x_1x_2 + x_2^2-21 &= 0\\
\left(-\frac{1}{3\lambda}\right)^2 + \left(-\frac{1}{3\lambda}\right)\left(-\frac{4}{3\lambda}\right) + \left(-\frac{4}{3\lambda}\right)^2-21 &= 0\\
\frac{1}{9\lambda^2} +\frac{4}{9\lambda^2} +\frac{16}{9\lambda^2} &= 21\\
\frac{21}{9\lambda^2} &= 21 \\
\lambda^{2} &= 1/9 \\
\lambda &= \pm 1/3.
\end{align*}

Finally, calculate $x_{1}^{\ast}, x_{2}^{\ast}$ and evaluate $f(x_{1}^{\ast}, x_2^{\ast})$ for each $\lambda$ to determine type of optimum
\begin{align*}
\lambda_{1} = \frac{1}{3} \Rightarrow &
\begin{cases}
x_{1} = -1\\
x_{2} = -4
\end{cases} &\Rightarrow
f(-1, -4) = 1 \quad &\text{global minimum}\\
\lambda_{2} = -\frac{1}{3} \Rightarrow &
\begin{cases}
x_{1} = 1\\
x_{2} = 4
\end{cases} &\Rightarrow
f(1, 4) = 29 \quad &\text{global maximum}\\
\end{align*}
